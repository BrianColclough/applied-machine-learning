{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset from ./titanic/train.csv\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./titanic/train.csv')\n",
    "test_data = pd.read_csv('./titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549be437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52a07712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88961195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589651e1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07679c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show types of data for each feature\n",
    "train_data.info()\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a0457",
   "metadata": {},
   "source": [
    "Looking at this, it seems that passengerID is a feature we can drop, since it’s just a unique identifier and won’t provide any discriminatory power. Ticket may be the same but I'll some testing to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3ec453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print feature names of dataframe\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a566140",
   "metadata": {},
   "source": [
    "I can build a pipeline with some custom preprocessing steps that extract a person's title, like Mr, Miss, etc. This might provide more insight and will reduce dimensionality after one-hot encoding compared to the unprocessed name field. I'm doing something similar for the deck extractor function, where we extract the cabin deck letter (A, B, C, etc.). This again reduces dimensionality after one-hot encoding while still retaining some classification power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class TitleExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        s = X.iloc[:, 0].astype(str)\n",
    "        titles = s.str.extract(r',\\s*([^\\.]+)\\.', expand=False).str.strip()\n",
    "        return titles.to_frame(name='Title')\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(['Title'])\n",
    "\n",
    "class DeckExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        s = X.iloc[:, 0].astype(str)\n",
    "        deck = s.str.extract(r'([A-Za-z])', expand=False)\n",
    "        return deck.to_frame(name='Deck')\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(['Deck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca79a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing with Title and Deck created and applied successfully\n",
      "Original shape: (891, 12)\n",
      "Processed shape: (891, 717)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Features we want to keep\n",
    "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
    "categorical_basic = ['Sex', 'Embarked', 'Ticket']\n",
    "\n",
    "# Pipelines\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "categorical_basic_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "title_pipeline = Pipeline(steps=[\n",
    "    ('title', TitleExtractor()),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "deck_pipeline = Pipeline(steps=[\n",
    "    ('deck', DeckExtractor()),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat_basic', categorical_basic_transformer, categorical_basic),\n",
    "        ('title', title_pipeline, ['Name']),\n",
    "        ('deck', deck_pipeline, ['Cabin'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Split X/y\n",
    "y = train_data['Survived']\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "\n",
    "train_data_processed = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "print(\"Preprocessing with Title and Deck created and applied successfully\")\n",
    "print(f\"Original shape: {train_data.shape}\")\n",
    "print(f\"Processed shape: {train_data_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb3727",
   "metadata": {},
   "source": [
    "### Feature Importance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_model(clf, X, y, seed=42, print_features=False):\n",
    "    # 10-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    accuracies = cross_val_score(clf, X, y, cv=skf, scoring='accuracy')\n",
    "    \n",
    "    print(f\"Mean accuracy: {accuracies.mean():.4f} ({chr(177)} {accuracies.std():.4f})\")\n",
    "    \n",
    "\n",
    "    if print_features:\n",
    "        clf.fit(X, y)\n",
    "        feature_names = preprocessing_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "        fi = pd.Series(clf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nTop features:\")\n",
    "        print(fi.head(25).to_string())\n",
    "        print(\"\\nLow-importance features:\")\n",
    "        print(fi[fi < 0.005].to_string())\n",
    "    \n",
    "    return accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8a497d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8182 (± 0.0240)\n",
      "\n",
      "Top features:\n",
      "num__Fare                0.214100\n",
      "num__Age                 0.206126\n",
      "title__Title_Mr          0.092376\n",
      "cat_basic__Sex_male      0.081787\n",
      "cat_basic__Sex_female    0.081104\n",
      "num__Pclass              0.066252\n",
      "num__SibSp               0.051980\n",
      "num__Parch               0.032385\n",
      "deck__Deck_n             0.029468\n",
      "title__Title_Mrs         0.028792\n",
      "title__Title_Miss        0.027012\n",
      "cat_basic__Embarked_S    0.014177\n",
      "cat_basic__Embarked_C    0.012176\n",
      "title__Title_Master      0.011070\n",
      "deck__Deck_E             0.008933\n",
      "cat_basic__Embarked_Q    0.007852\n",
      "deck__Deck_D             0.006880\n",
      "deck__Deck_C             0.006748\n",
      "deck__Deck_B             0.006573\n",
      "deck__Deck_A             0.002807\n",
      "deck__Deck_F             0.001914\n",
      "title__Title_Rev         0.001885\n",
      "title__Title_Dr          0.001774\n",
      "deck__Deck_G             0.001582\n",
      "title__Title_Major       0.001101\n",
      "\n",
      "Low-importance features:\n",
      "deck__Deck_A                 0.002807\n",
      "deck__Deck_F                 0.001914\n",
      "title__Title_Rev             0.001885\n",
      "title__Title_Dr              0.001774\n",
      "deck__Deck_G                 0.001582\n",
      "title__Title_Major           0.001101\n",
      "title__Title_Col             0.000825\n",
      "title__Title_Capt            0.000624\n",
      "title__Title_Sir             0.000436\n",
      "deck__Deck_T                 0.000297\n",
      "title__Title_Don             0.000284\n",
      "title__Title_Ms              0.000260\n",
      "title__Title_Jonkheer        0.000253\n",
      "title__Title_Mlle            0.000066\n",
      "title__Title_Lady            0.000039\n",
      "title__Title_the Countess    0.000035\n",
      "title__Title_Mme             0.000023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82222222, 0.83146067, 0.79775281, 0.78651685, 0.7752809 ,\n",
       "       0.80898876, 0.83146067, 0.85393258, 0.84269663, 0.83146067])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "train_model(rf, train_data_processed, y, 28, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743bc24",
   "metadata": {},
   "source": [
    "Looks like we won't be needing the ticket field, it doesn't provide much value and creates a whole lot of extra columns when we one-hot encode.\n",
    "\n",
    "Now I'm going to train the basic set of models to check the performance of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "246e4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8126 (± 0.0285)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82222222, 0.84269663, 0.7752809 , 0.78651685, 0.76404494,\n",
       "       0.79775281, 0.83146067, 0.85393258, 0.83146067, 0.82022472])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Features we want to keep\n",
    "categorical_basic = ['Sex', 'Embarked']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat_basic', categorical_basic_transformer, categorical_basic),\n",
    "        ('title', title_pipeline, ['Name']),\n",
    "        ('deck', deck_pipeline, ['Cabin'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "train_data_processed = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', RandomForestClassifier(n_estimators=300, random_state=42))\n",
    "])\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "train_model(rf, X, y, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b61a5912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8193 (± 0.0278)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.79775281, 0.80898876, 0.80898876, 0.7752809 ,\n",
       "       0.84269663, 0.78651685, 0.86516854, 0.82022472, 0.85393258])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svm', LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "train_model(svm, X, y, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ffabe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6790 (± 0.0423)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71111111, 0.68539326, 0.62921348, 0.69662921, 0.62921348,\n",
       "       0.75280899, 0.70786517, 0.65168539, 0.70786517, 0.61797753])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RBF SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf= Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svm', SVC(kernel='rbf', random_state=42))\n",
    "])\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "train_model(rbf, X, y, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35093814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7407 (± 0.0606)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81111111, 0.74157303, 0.76404494, 0.75280899, 0.66292135,\n",
       "       0.86516854, 0.69662921, 0.68539326, 0.75280899, 0.6741573 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "nb = Pipeline(steps=[   \n",
    "    ('preprocessor', preprocessor),\n",
    "    # transform to array\n",
    "    ('to_array', FunctionTransformer(lambda x: x.toarray())),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "train_model(nb, X, y, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6db10547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8159 (± 0.0304)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84444444, 0.7752809 , 0.78651685, 0.78651685, 0.80898876,\n",
       "       0.86516854, 0.78651685, 0.82022472, 0.83146067, 0.85393258])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(solver='liblinear', max_iter=400, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "train_model(lf, X, y, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3ce5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best params: {'clf__class_weight': 'balanced', 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__n_estimators': 800}\n",
      "Best CV ROC-AUC: 0.8835273714153024\n",
      "Hold-out ROC-AUC: 0.8477602108036891\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8393    0.8545    0.8468       110\n",
      "           1     0.7612    0.7391    0.7500        69\n",
      "\n",
      "    accuracy                         0.8101       179\n",
      "   macro avg     0.8002    0.7968    0.7984       179\n",
      "weighted avg     0.8092    0.8101    0.8095       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y = train_data['Survived']\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "\n",
    "# Train/validation split for final evaluation\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid (tune 'clf__*')\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [200, 400, 800],\n",
    "    'clf__max_depth': [None, 8, 12, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=rf_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring={'roc_auc': 'roc_auc', 'accuracy': 'accuracy', 'f1': 'f1'},\n",
    "    refit='roc_auc',            # refit the best by ROC-AUC\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "gs.fit(X_tr, y_tr)\n",
    "\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", gs.best_score_)\n",
    "\n",
    "# Evaluate on hold-out set\n",
    "y_pred = gs.predict(X_te)\n",
    "y_proba = gs.predict_proba(X_te)[:, 1]\n",
    "print(\"Hold-out ROC-AUC:\", roc_auc_score(y_te, y_proba))\n",
    "print(\"Classification report:\\n\", classification_report(y_te, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9d799c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8339 (± 0.0257)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.85555556, 0.83146067, 0.80898876, 0.82022472, 0.83146067,\n",
       "       0.88764045, 0.79775281, 0.85393258, 0.84269663, 0.80898876])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tain a model using the best parameters\n",
    "rf_best = gs.best_estimator_\n",
    "\n",
    "X = train_data.drop(columns=['Survived'])\n",
    "y = train_data['Survived']\n",
    "\n",
    "best_model = Pipeline(steps=[   \n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced', max_depth=20, max_features='sqrt', min_samples_split=5, min_samples_leaf=2, n_estimators=800))\n",
    "])\n",
    "\n",
    "train_model(best_model, X, y, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afac2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model to predict the test set\n",
    "y_pred = best_model.predict(test_data)\n",
    "\n",
    "def save_preds(_fn, _y_pred, _df):\n",
    "    import csv\n",
    "    with open(_fn, 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(['PassengerId', 'Survived'])\n",
    "        for yid, ypred in zip(_df['PassengerId'], _y_pred):\n",
    "            writer.writerow([yid, ypred])\n",
    "\n",
    "save_preds('predictions_colclough.csv', y_pred, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af988c09",
   "metadata": {},
   "source": [
    "I was able to make my first submission on kaggle using this the output here. This was a really fun assignment! I decided to go with the random forrest classifier as it and the linear svm were very close in score, but I know how robust random forrest classifiers can be. In the assignment instructions had also mentioned using a random forest and getting a 79% score, which I thought would be a good benchmark for my classifier.\n",
    "\n",
    "![Alt text](./score.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
